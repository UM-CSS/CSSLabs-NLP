{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's in an online dating profile? \n",
    "\n",
    "People say a lot about themselves in online dating profiles, especially on sites like OKCupid that encourage people to answer questions. Thus, we can learn a lot about people by studying what they write. OKC has made some of their profile data from San Francisco public. We will be using that data in this lab to explore different cultural questions. \n",
    "\n",
    "Our first question is whether and how men and women talk about themselves differently in their profiles. Popular culture is constantly telling us that men and women have different interests, hobbies, and relationship goals. Yet there are also many examples of women who like stereotypically masculine things and men who like feminine ones. This is especially interesting in online dating, because people are seeking partners with similar interests and relationship goals. Finding a partner would be hard for straight men and women if these two groups had very different interests. \n",
    "\n",
    "OKC shared 59,946 profiles though -- way too many to read! Computers can read them all and tell us how common different words are. So our first approach will be simple. We can ask \n",
    "1. Which words are used the most by men and women? \n",
    "2. Which words are used often by men but not women, and vice versa? \n",
    "\n",
    "At the end of the lab, you'll be able to ask this question about other social groups too (like sexual orientation, race/ethnicity, age, level of education, even whether someone likes dogs or cats).\n",
    "\n",
    "@Author: [Jeff Lockhart](http://www-personal.umich.edu/~jwlock/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup\n",
    "### Import the packages we'll use.\n",
    "- Packages contain a bunch of useful code others have written to make our jobs easier.\n",
    "- `%matplotlib inline` lets us see charts and plots right here in the notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import nltk\n",
    "# If you have used NLTK or run this code before, you can comment out this download line\n",
    "nltk.download('popular', quiet=True)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import regexp_tokenize \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and prepare the data\n",
    "This code checks whether you have the data. If you don't, it will download and prepare it for you. To see how it works, look at lab `1 Data munging` which explains it in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'download_and_clean_data.py'\n",
    "print('Ready to go!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = pd.read_csv('data/clean_profiles.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show how many rows and columns the data has\n",
    "profiles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the names of the columns\n",
    "profiles.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the first few rows of data\n",
    "profiles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For laptop or personal computer users\n",
    "Run this code so that you're working with a smaller amount of data and don't crash your computer. It takes a simple random sample of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = profiles.sample(20000)\n",
    "profiles = profiles.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### While we're at it, let's make some helper functions for later.\n",
    "Run this code, but don't worry about these now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_example(text, word, context=False):\n",
    "    #regex for selecting the whole word from a stem\n",
    "    expr = word + '\\w*'\n",
    "    \n",
    "    if context:\n",
    "        #regex for selecting a stem and also the 2 words before and after it\n",
    "        #this lets us see the context in which it is used\n",
    "        expr = '\\w*\\W*\\w*\\W*' + word + '\\w*\\W*\\w*\\W*\\w*'\n",
    "\n",
    "    return re.search(expr, text, re.I).group()\n",
    "\n",
    "def get_examples(data, word, n=5, context=True, limit_col=None, limit_val=None):\n",
    "    if word.endswith('i'):\n",
    "        #the Porter2 stemmer sometimes adds 'i' to stems. This trimms it off.\n",
    "        word = word[:-1]\n",
    "    \n",
    "    #restrict to just some group of interest\n",
    "    if limit_col is not None:\n",
    "        data = data[data[limit_col] == limit_val]\n",
    "    \n",
    "    #sample our data so this operation goes faster\n",
    "    if data.shape[0] > 1000:\n",
    "        data = data.sample(1000)\n",
    "    \n",
    "    #find profiles with the word in them\n",
    "    tmp = data.text.apply(lambda x: word in x)\n",
    "    #select n random profiles that have the word\n",
    "    count = tmp.sum()\n",
    "    \n",
    "    #if we wanted more examples than there are\n",
    "    if n > count:\n",
    "        n = count\n",
    "    tmp2 = data[tmp].text.sample(n).values\n",
    "    \n",
    "    #get an example out of each profile we selected\n",
    "    tmp = []\n",
    "    for t in tmp2:\n",
    "        tmp.append(extract_example(t, word, context))\n",
    "    \n",
    "    return tmp\n",
    "\n",
    "def unstem(word, data, n=50):\n",
    "    if word.endswith('i'):\n",
    "        #the Porter2 stemmer sometimes adds 'i' to stems. This trimms it off.\n",
    "        word = word[:-1]\n",
    "\n",
    "    #use the function we made before to get examples of the stem\n",
    "    tmp = get_examples(data, word=word, n=n, context=False)\n",
    "    \n",
    "    #count up and return the most common form of the word matching the stem\n",
    "    return Counter(tmp).most_common(1)[0][0]\n",
    "\n",
    "def clean_index(df, text):\n",
    "    #replaces stems in the index of a dataframe with whole words\n",
    "    df.reset_index(inplace=True)\n",
    "    df['index'] = df['index'].progress_apply(unstem, data=text)\n",
    "    df.set_index('index', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tokenizing text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's peak at an example of the text so we know what we're working with.\n",
    "This code shows us the text for the 6th profile (python counts from 0, so the first profile is #0, the second is #1, and so on). 5 here could be any number. Try changing it to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.text[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want to split the text into words so we can count them. Here's a simple first try.\n",
    "- The `split()` function, like its name suggests, splits text into chunks. If we split on spaces (the default), it will split the text into words. Let's `apply` it to the `text` of our `profiles`.\n",
    "- Notice that this is a little messy. The punctuation and some HTML things are mixed in with our words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = profiles['text'].apply(lambda x: x.split())\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the most common words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = Counter(chain.from_iterable(tmp))\n",
    "tmp.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection: types of words\n",
    "- There are many different types of words in English. We have nouns, pronouns, adjectives, verbs, adverbs, conjunctions, prepositions, articles, and more!\n",
    "- Notice above that many of the most common words are prepositions, conjunctions, and articles (\"the,\" \"a,\" \"but,\" \"of,\" \"to,\" etc.). \n",
    "- Pick three types of words and write a brief sentence explaining what we could learn from studying how people use each word type below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect here:\n",
    "\n",
    "- .\n",
    "- .\n",
    "- .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words\n",
    "- Researchers often decide to ignore some types of words that they are not interested in. These are called \"stop words.\" It is common to remove them so we can focus on the words we think matter. [Learn more](https://en.wikipedia.org/wiki/Stop_words)\n",
    "- The common set of stop words for English includes conjunctions, prepositions, articles, and pronouns. It is so comon that it is built in for people to use. \n",
    "    - This lab makes an exception to the normal list of stop words and keeps the pronouns because some research shows that pronoun use matters in dating. You could add more words to remove or keep, depending on what you think is important, but we will use these for the lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show stop word list\n",
    "sw = set(stopwords.words('english'))\n",
    "print('Here is the list of common English stop words:\\n\\n', sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \n",
    "              'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', \n",
    "              'himself', 'she', 'her', 'hers', 'herself', 'they', 'them', 'their',\n",
    "              'theirs', 'themselves']\n",
    "\n",
    "for k in keep_words:\n",
    "    sw.discard(k) #could use remove if we wanted keyerrors\n",
    "    \n",
    "print(\"Here are the words we will remove:\\n\\n\", sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better tokenizing\n",
    "- In the most common words, we also saw some messy stuff like `\\>`.\n",
    "- This code cleans the text up a bit. \n",
    "    - We remove all the HTML code from the text\n",
    "    - We remove some other non-word text like \"www\"\n",
    "    - We convert all the text to lowercase, so that the computer sees \"Dog\", \"DOG\", and \"dog\" as the same word.\n",
    "    - We remove all our stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text, sw):\n",
    "    t = BeautifulSoup(text, 'lxml').get_text()\n",
    "    \n",
    "    bad_words = ['http', 'www', '\\nnan']\n",
    "    for b in bad_words:\n",
    "        t = t.replace(b, '')\n",
    "    \n",
    "    t = t.lower()\n",
    "    t = regexp_tokenize(t, '\\w+')\n",
    "    \n",
    "    final = []\n",
    "    for w in t:\n",
    "        if w not in sw:\n",
    "            final.append(w)\n",
    "    \n",
    "    return final\n",
    "\n",
    "profiles['tokens'] = profiles['text'].progress_apply(clean, sw=sw)\n",
    "profiles.tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. Comparing the words used by men and women\n",
    "#### Step 1: We separate the profiles of women and men.\n",
    "We'll limit it to straight people for now. You'll have the chance to explore other groups later in the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "men = profiles[(profiles['sex'] == 'm') & (profiles['orientation'] == 'straight')]\n",
    "women = profiles[(profiles['sex'] == 'f') & (profiles['orientation'] == 'straight')]\n",
    "\n",
    "men.tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Counting how often each gender uses each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this counts how many times each word shows up\n",
    "mens_words = Counter(chain.from_iterable(men.tokens)) \n",
    "\n",
    "print('Ten most common words used by men:')\n",
    "mens_words.most_common(10) #this shows us the 10 most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ten most common words used by women:')\n",
    "womens_words = Counter(chain.from_iterable(women.tokens))\n",
    "womens_words.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the most popular words are basically the same for each gender.\n",
    "\n",
    "#### Step 3a: Put the word counts in a data frame so they're easier to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn the two word count data into a single dataframe so it's easy to work with \n",
    "tmp = {'women': womens_words, 'men': mens_words}\n",
    "popular_words = pd.DataFrame(tmp)\n",
    "\n",
    "#this cleans it up a bit by putting in 0 for all the words we didn't see\n",
    "popular_words = popular_words.fillna(0).astype(int)\n",
    "\n",
    "popular_words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, the words are sorted alphabetically. That's not super useful, though.\n",
    "\n",
    "#### Step 3b: Sort the words by popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = popular_words.sort_values(by='women', ascending=False)\n",
    "popular_words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Convert those word counts to frequencies (percent of total words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the word counts into percents (i.e. what percent of total words are x)\n",
    "popular_words['men'] = (popular_words['men'] /  popular_words['men'].sum())*100\n",
    "popular_words['women'] = (popular_words['women'] /  popular_words['women'].sum())*100\n",
    "\n",
    "#create a column \"max\" that has the word's maxmum popularity (in either men or women)\n",
    "popular_words['max'] = popular_words.max(axis=1)\n",
    "\n",
    "#show the most popular words overall\n",
    "popular_words.sort_values(by='max', ascending=False, inplace=True)\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see some typical examples of how these words are used\n",
    "- You can change the number `6` to show more or less examples.\n",
    "- You can change the world `'love'` to any word you're interested in. \n",
    "    - \"love\" is interesting because it is not always used the way we might expect in a dating profile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_examples(data=profiles, word='love', n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look just at examples of how men use the word 'love'\n",
    "- You can change `limit_col` to something other than `sex` if you want to look at a different attribute.\n",
    "- You can change `limit_val` to something other than `m` if you want to look at a different group within the attribute (e.g. change it to `f` if you want to see women's use)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_examples(data=profiles, word='love', n=6, limit_col='sex', limit_val='f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most words are very uncommon\n",
    "- The X axis in this histogram is the word popularity (percent of total words that are this word). \n",
    "- The Y axis is the number of words that have that level of popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show a histogram with 100 bins\n",
    "popular_words['max'].plot.hist(bins=100, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Look at just the 1000 most popular words\n",
    "- Note that the shape of the distribution looks similar, but the Y axis is much smaller ($ 10^3 $ instead of $ 10^5 $), meaning we have removed many extremely uncommon words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select only the 1000 most popular words\n",
    "popular_words = popular_words.sort_values(by='max', ascending=False).head(1000)\n",
    "\n",
    "#show the histogram again\n",
    "popular_words['max'].plot.hist(bins=100, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Figure out which words are more popular with one gender than the other\n",
    "- Here we calculate how many times different the usage of words by men or women is, so if men use a word twice as often as women use the same word, then then men's use is 2 times different. \n",
    "- Like we saw before, both groups use the most popular words about the same amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def times_diff(row):\n",
    "    #calculate how many times more men use a word than women\n",
    "    #or vice versa if women use the word more\n",
    "    if row.men > row.women:\n",
    "        return row.men / row.women\n",
    "    else:\n",
    "        return -1 * (row.women / row.men)\n",
    "    \n",
    "popular_words['times_diff'] = popular_words.apply(times_diff, axis=1)\n",
    "popular_words = popular_words.sort_values(by='max', ascending=False)\n",
    "\n",
    "print('Most popular words:')\n",
    "popular_words.head(10).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at the words that are most different between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Words men use more than women:')\n",
    "popular_words.sort_values(by='times_diff', ascending=False).head(15).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Words women use more than men:')\n",
    "popular_words.sort_values(by='times_diff', ascending=True).head(15).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection: repeated words\n",
    "- Do you see any words that show up more than once in the lists above? \n",
    "- Chances are, both \"computer\" and \"computers\" show up for men (San Francisco men really like computers...)\n",
    "- This happens a lot. We know those are the same word, but to the computer they are different. Computers are very literal, so because \"computer\" and \"computers\" dont have exactly the same letters in exactly the same order, it thinks they are different. \n",
    "- Reflect: give a few examples of times this might happen, other than plural words with an \"s\" added on the end. \n",
    "    - Hint: look at the word lists above, or think about other word endings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect here:\n",
    "\n",
    "- .\n",
    "- ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Getting cleaner results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with word endings\n",
    "- When researchers want to match words that have the same base but different endings, they do something called \"stemming.\" \n",
    "- Stemming grabs just the \"stem\" of each word (e.g. the stem of both \"run\" and \"runs\" is \"run\"). When the words are converted to their stems, the computer sees them as the same. [Learn more](https://en.wikipedia.org/wiki/Stemming)\n",
    "- Stemming English is a little complicated, because English spelling has so many quirks. Luckily, experts have already done the hard work and we can use their tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#snowball English (aka porter2) is the best general stemmer\n",
    "stemmer = SnowballStemmer(\"english\") \n",
    "\n",
    "def stem(t):\n",
    "    out = []\n",
    "    for w in t:\n",
    "        out.append(stemmer.stem(w))\n",
    "    return out\n",
    "\n",
    "print(\"Stemming words from profile text...\")\n",
    "profiles['stems'] = profiles['tokens'].progress_apply(stem)\n",
    "profiles.stems.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These helper functions let us do the same things we did before without rewriting all the steps each time.\n",
    "You don't have to worry about what's in them right now. Just run the cell and scroll down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for summarizing word use by a trait\n",
    "def times_diff2(row, group, ref):\n",
    "    if row[ref] > row[group]:\n",
    "        return -1 * (row[ref] / row[group])\n",
    "    else:\n",
    "        return row[group] / row[ref]\n",
    "\n",
    "def count(data, per_person):\n",
    "    #count the people in each category\n",
    "    l = len(data)\n",
    "\n",
    "    #apply the right aggregation function, depending whether we want \n",
    "    #most common words, or words used by most people\n",
    "    if per_person:\n",
    "        data = chain.from_iterable([set(x) for x in profiles.stems])\n",
    "    else:\n",
    "        data = chain.from_iterable(data)\n",
    "            \n",
    "    c = Counter(data)\n",
    "    \n",
    "    return c, l\n",
    "\n",
    "def word_use(df, att, ref=None, per_person=False, undostems=False):\n",
    "    #list all of the categories in this column\n",
    "    types = list(df[att].value_counts().index.values)\n",
    "    #variables that will store our results\n",
    "    data = {}\n",
    "    lens = {}\n",
    "    \n",
    "    print(\"Counting the words used by each group...\")\n",
    "    for t in types:\n",
    "        #get the stems for each category\n",
    "        tmp = df[df[att] == t].stems\n",
    "        #count how often each is used\n",
    "        data[t], lens[t] = count(tmp, per_person)\n",
    "        \n",
    "        #also compute the inverse of each category\n",
    "        tmp = df[df[att] != t].stems\n",
    "        data['not_'+str(t)], lens['not_'+str(t)] = count(tmp, per_person)        \n",
    "        \n",
    "    #convert those results to a pandas data frame for easy handling\n",
    "    popular_words = pd.DataFrame(data)\n",
    "    \n",
    "    print('Calculating percentages...')\n",
    "    # convert the counts in each column to percents\n",
    "    for t in popular_words.columns:\n",
    "        n = lens[t] #if we want percent of people\n",
    "        \n",
    "        if not per_person: #if we want percent of total words \n",
    "            n = popular_words[t].sum()\n",
    "        \n",
    "        popular_words[t] = (popular_words[t] / n) * 100\n",
    "    \n",
    "    print('Selecting the most popular words...')\n",
    "    #find overall most popular words\n",
    "    popular_words['max'] = popular_words.max(axis=1)\n",
    "    #sort the words and select the top 1000 most popular\n",
    "    popular_words = popular_words.sort_values(by='max', ascending=False)\n",
    "    popular_words = popular_words.head(1000)\n",
    "\n",
    "    print('Calculating most distinctive words...')\n",
    "    #calculate the rate each type of person uses these words relative to others\n",
    "    for t in types:\n",
    "        r = ref\n",
    "        \n",
    "        if ref == None: #if we do not have a reference category, use the inverse\n",
    "            r = 'not_'+str(t)\n",
    "            \n",
    "        if t != ref: #don't compare a trait to itself\n",
    "            #apply our times_diff2 function\n",
    "            popular_words['times_diff_'+str(t)] = popular_words.apply(times_diff2, \n",
    "                                                                 group=t, \n",
    "                                                                 ref=r, \n",
    "                                                                 axis=1)\n",
    "\n",
    "    #remove the inverse columns we created\n",
    "    popular_words = popular_words.drop(popular_words.filter(regex='not_'), axis=1)\n",
    "    \n",
    "    if undostems:\n",
    "        print('Cleaning up word stems for readability...')\n",
    "        popular_words = clean_index(popular_words, df)\n",
    "    \n",
    "    print('Done!')\n",
    "    return popular_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try comparing men's and women's words again with stems this time\n",
    "- The top words are somewhat different now that we're counting similar words as the same.\n",
    "- We see word stems rather than whole words listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = word_use(profiles, att='sex')\n",
    "popular_words = popular_words.sort_values(by='times_diff_m', ascending=False)\n",
    "print(\"Men's words:\")\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Those word stems in our table are a little hard to read. Let's change that.\n",
    "- The `undostems=True` option converts the stems back to whole words before showing us the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = word_use(profiles, att='sex', undostems=True)\n",
    "popular_words = popular_words.sort_values(by='times_diff_m', ascending=False)\n",
    "print(\"Men's distinctive words:\")\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = popular_words.sort_values(by='times_diff_f', ascending=False)\n",
    "print(\"Women's distinctive words:\")\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO make this a question with repetition \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But, wait! Not all profiles have the same number of words. \n",
    "- What if a single man just wrote \"computer\" a thousand times and that is skewing our results?\n",
    "- With `per_person=True` we can see which words are used by the most different people, rather than which words are most common out of all the words used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = word_use(profiles, att='sex', per_person=True, undostems=True)\n",
    "print(\"Men's words:\")\n",
    "popular_words.sort_values(by='times_diff_m', ascending=False).head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Women's words:\")\n",
    "popular_words.sort_values(by='times_diff_f', ascending=False).head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Your turn to try it with another trait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options (traits)\n",
    "We have a lot more information about people than just whether they're men or women. Try the analysis again with one of these other traits. (Expand for a list.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- age_group (How old someone is. Youngest users are 18.)\n",
    "    - categories: ['10', '20', '30', '40', '50']\n",
    "- body (self-described)\n",
    "    - categories: ['average', 'fit', 'thin', 'overweight', 'unknown']\n",
    "- alcohol_use\n",
    "    - categories: ['yes', 'no']\n",
    "- drug_use\n",
    "    - categories: ['yes', 'no']\n",
    "- edu (highest degree completed)\n",
    "    - categories: ['`<HS`', 'HS', 'BA', 'Grad_Pro', 'unknown'] \n",
    "- race_ethnicity\n",
    "    - categories: ['Asian', 'Black', 'Latinx', 'White', 'multiple', 'other']\n",
    "- height_group (whether someone is over or under six feet tall)\n",
    "    - categories: ['under_6', 'over_6']\n",
    "- industry (what field they work in)\n",
    "    - categories: ['STEM', 'business', 'education', 'creative', 'med_law', 'other'] \n",
    "- kids (whether they have children)\n",
    "    - categories: ['yes', 'no']\n",
    "- orientation\n",
    "    - categories: ['straight', 'gay', 'bisexual']\n",
    "- pets_likes (what pets they like)\n",
    "    - categories: ['both', 'dogs', 'cats', 'neither']\n",
    "- pets_has (what pets they have)\n",
    "    - categories: ['both', 'dogs', 'cats', 'neither']\n",
    "- pets_any (whether they have pets or not)\n",
    "    - categories: ['yes', 'no']\n",
    "- religion\n",
    "    - categories: ['christianity', 'catholicism', 'judaism', 'buddhism', 'none', 'other'] \n",
    "- sex\n",
    "    - categories: ['m', 'f']\n",
    "- smoker\n",
    "    - categories: ['yes', 'no']\n",
    "- languages\n",
    "    - categories: ['multiple', 'English_only'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to (steps)\n",
    "#### Step 1a: Decide which of the traits above you want to look at.\n",
    "#### Step 1b: Load the profile data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = pd.read_csv('data/clean_profiles.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Step 2a: If you want, limit the data to just men or women.\n",
    "- For everyone, leave this code how it is.\n",
    "- For only men, remove the `#`\n",
    "- For only women, remove the `#` and change the `'m'` in this line to `'f'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profiles = profiles[profiles['sex'] == 'm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2b: If you're running this on your personal computer\n",
    "Run this code to use just a sample of the data set, because the full data is big enough to crash most personal computers. You can make the sample bigger or smaller by changing the number here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = profiles.sample(20000)\n",
    "profiles.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Tokenize and stem the text for these profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tokenizing...\")\n",
    "profiles['tokens'] = profiles['text'].apply(clean, sw=sw)\n",
    "print(\"Stemming...\")\n",
    "profiles['stems'] = profiles['tokens'].apply(stem)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Compute the word usage statistics for your chosen attribute.\n",
    "You can change the code below:\n",
    "- You can change `att='age_group'` to your attribute of interest (e.g. `pets_likes` or `orientation`)\n",
    "- The `per_person` and `undostems` are the same as we saw before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = word_use(profiles, att='age_group', per_person=True, undostems=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5a: Look at the results.\n",
    "First, let's just see what columns we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head(2).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5b: Looking at the most distinctive words by category\n",
    "You can change two things in this code:\n",
    "1. Change `'times_diff_10'` to the name of the column you want to sort by, i.e. the column you want to see the most popular words in. \n",
    "2. Change the number in `head(10)` to a bigger or smaller number to see more or less rows of output.\n",
    "\n",
    "You can paste this line into more cells below and change it again to show different groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(by='times_diff_10', ascending=False).head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(by='times_diff_20', ascending=False).head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(by='times_diff_30', ascending=False).head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(by='times_diff_40', ascending=False).head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(by='times_diff_50', ascending=False).head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. What we learned\n",
    "Expand for more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Sociology & Gender\n",
    "1. Overall, the most common words in online dating are the same for men and women in San Francisco. What they say about themselves is not that different. \n",
    "2. There are some words that men use much more often than women, and vice versa. These fit stereotypical gender roles: for example, men in San Francisco are much more likely to talk about computers, startups, engineering, and sports. And women are much more likely to talk about food (e.g. baking and chocolate) or feelings (adore, laughter). \n",
    "3. There are many possible causes for these differences in word use. For example, it is often taboo for men to talk about their feelings, so they may mention them less here because of social expectations rather than because they are less emotional. Social factors can also increase expression: for instance, women typically do the majority of food preparation in American families, so it is not surprising that they are more likely than men to talk about it in dating profiles. \n",
    "4. Not every person conforms to these broad patterns. Only 10-20% of these men mention computers. A similar percent of the women mention baking. Some women talk about computers, and some men talk about baking. Most people aren't using these very gendered words at all. What we showed is that there are broad patterns of some topics being much more popular with men or women, and that these patterns line up with common cultural expectations of gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Text analysis\n",
    "1. **Tokenizing** is the process of splitting text into words (tokens). Simple approaches can separate words based on spaces, but punctuation, HTML, and other things can make this more complicated. \n",
    "2. **Stop words** are words that are common but don't give us much information. They're often removed before we do analysis.\n",
    "3. **Stemming** lets us combine similar words like \"runs\" and \"running\" by looking at the stem of the words (in this case, \"run\"). \n",
    "4. Most words are not very common. [Oxford Dictionaries](https://en.oxforddictionaries.com/explore/how-many-words-are-there-in-the-english-language) lists over 171,000 currently used English words, but as we saw, only a few words show up in more than a few profiles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect:\n",
    "- In the space below, write a few sentences in response to each of these questions:\n",
    "    1. What did you learn about the role of gender and online dating from this lab?\n",
    "    2. What trait did you pick for the try it yourself part? What did you learn about that trait? \n",
    "    3. We made a number of choices along the way: which stop words to exclude, whether to \"stem\" words, and more. Pick one of these choices and say how you think our findings might have been different if we made a different choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect here:\n",
    "\n",
    "1. \n",
    "\n",
    "2. \n",
    "\n",
    "3. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
